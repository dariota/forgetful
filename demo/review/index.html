<html>
	<head>
		<meta charset="utf-8"/>
		<title>ntun.es - forgetful project - Literature Review/State of the Art</title>
		<link rel="stylesheet" type="text/css" href="/styles/default.css">
	</head>
	<body>
		<h1 id="literature-reviewstate-of-the-art">Literature Review/State of the Art</h1>
		<p>There are a number of aspects to consider when determining what the appropriate literature/state of the art is.</p>
		<p>For</p>
		<ul>
		<li>Comparison of the plugin and the platform it built on: other static analysis tools</li>
		<li>Alternative methods to approach the problem: profiling and runtime tools</li>
		<li>Allocator methods and their performance: papers comparing them</li>
		<li>Validation of the project space: alternative allocation methods and allocators to reduce allocation burden</li>
		<li>Discussion of results: typical performance increase from compiler optimisations</li>
		</ul>
		<h2 id="plugin-and-its-platform">Plugin and its Platform</h2>
		<p>Three options are examined - <em>Frama-C</em> itself, <em>Infer</em>, and <em>clang-analyzer</em>.</p>
		<h3 id="frama-c">Frama-C</h3>
		<p>While <a href="http://frama-c.com/index.html"><em>Frama-C</em></a> was a decent choice for its extensibility and availability of introductory <a href="http://frama-c.com/plugins.html">guides to plugin development</a>, finding assistance/documentation for it was relatively difficult, even for basic functionality of <a href="http://frama-c.com/value.html">EVA</a>.<br />
		Perhaps a better choice would have been to modify/extend a static analysis tool with a more active and modern community (irregular releases consist of <a href="https://github.com/Frama-C/Frama-C-snapshot/commits/master">single dumps of source code</a>, with the first beta release in <a href="http://frama-c.com/download_hydrogen.html">March 2008</a>), which likely would've made it easier to dig into the codebase even if it wasn't built as intentionally for extensibility.<br />
		<em>Frama-C</em>'s (open source) community is not hugely active, with only a few <a href="https://bts.frama-c.com/dokuwiki/doku.php?id=mantis:frama-c:external_plugins">external plugins</a> available, and not many plugins having been created between its initial release a decade ago and now.</p>
		<h3 id="infer">Infer</h3>
		<p>To the end of finding a large and active community, Facebook's <a href="http://fbinfer.com/"><em>Infer</em></a> might have been a better choice. By its own description, &quot;Infer checks for null pointer dereferences, memory leaks, coding conventions and unavailable API’s&quot;, it may also have been well suited to the problem thanks to its emphasis on memory issues and tracking memory.<br />
		Facebook first open-sourced <em>Infer</em> in <a href="https://github.com/facebook/infer/commit/b8982270f2423864c236ff8dcdbeb5cd82aa6002">June of 2015</a>, at which point it already supported C, Objective-C, C++, Java (≤ 1.7) and contained ~100k LoC. Since then, it has averaged 4-6 commits per day (dependending on whether you count weekends), now has ~300k LoC, and supports Java 8 as well as the original languages.<br />
		While it wasn't explictly designed for modularity like <em>Frama-C</em>, its <a href="https://github.com/facebook/infer/tree/master/infer/src">internal structure for checkers</a> is consistent and logical, which should make the addition of new checkers not prohibitively difficult.</p>
		<h3 id="clang-analyzer">clang-analyzer</h3>
		<p><a href="http://clang-analyzer.llvm.org/"><em>clang-analyzer</em></a>, which <em>Infer</em> is built on, is the only analyser in this list not written in OCaml, instead being in C++ to match the rest of the clang codebase. Among <a href="http://clang-analyzer.llvm.org/available_checks.html">features listed in its documentation</a> are a few memory analysis checkers (null, double free, stack reference escape detection) that could prove to be a useful base to build off. My familiarity with C++ (at least compared to my lack of familiarity with OCaml) could also have proven useful in development, reducing delays.<br />
		<em>clang-analyzer</em>'s development is much less active than <em>Infer</em>'s, but still more active (or at least more frequently updated) than <em>Frama-C</em>'s. It also has mailing lists and other community communication channels which could have been useful. It's the oldest of the three, <a href="https://github.com/llvm-mirror/clang/commit/e4e633400b1993c1174b47b774fa015220fa695c">started in September 2007</a>, but has had a huge amount of development since then (a caveat here: its full development lifecycle is public, from inception to its current state, unlike the other two, which can make it seem more active).<br />
		One unique mark against <em>clang-analyser</em> is its heavy emphasis on OS X related features and tutorials/setup instructions revolving around assumptions of the use of Apple hardware and software, which could cause minor delays in development.</p>
		<h2 id="alternative-approaches">Alternative Approaches</h2>
		<p>Other than static analysis/compile-time checking, run-time analysis can also be used to surface issues in the code. This profiling has an added benefit that (used properly), it can better reflect performance under real workloads. There are three main ways of achieving this, which are all different levels of the same thing.</p>
		<h3 id="custom-built-wrapper-functions">Custom Built Wrapper Functions</h3>
		<p>The first method involves a custom allocator wrapper function, which is the approach taken by <code>cURL</code>. In this method, calls to memory management functions are intercepted by redefining them to instead use the custom allocators, using something like <code>#define malloc(size) curl_domalloc(size, __LINE__, __FILE__)</code> to intercept calls and add in debugging information.<br />
		Usage of this system can usually be enabled or disabled at compile time by defining or undefining certain symbols, and a detailed implementation can be seen <a href="https://github.com/curl/curl/blob/67bd4ab19e2903b45b66278956801a681fc35520/lib/memdebug.h">in <code>cURL</code> itself</a>.<br />
		This method has the obvious downside that the system must be maintained by its users, who usually have goals orthogonal to it. However, it also allows the most fine-grained control of the three methods, and can easily be extended to also track other functions.</p>
		<h3 id="provided-allocator-wrapper-functions">Provided Allocator Wrapper Functions</h3>
		<p>When the fine-grained control of intercepting any given function, or adding more things to profile is not needed, wrapper functions can be found already written available online to be compiled along with your existing code.<br />
		Similar to the above, these intercept calls to memory management functions, outputting profiling data to a specified log file. One such example is <a href="https://panthema.net/2013/malloc_count/"><em>malloc_count</em></a>, which can also track stack usage. Since these projects are more focused on this specific task, they also attempt to meet standards, which allows the user to use their profiling data with existing graphing tools for memory profiling dumps.<br />
		While this method doesn't have the advantage of fine-tuned control of what exact data is dumped nor which functions are intercepted, it also doesn't suffer the disadvantages of maintenance and development of the system. It also benefits over the next method by being faster.</p>
		<h3 id="run-time-profilinginterception">Run-time Profiling/Interception</h3>
		<p>Without requiring function interception to be included in code at compile time, hooks can be used to intercept calls to any given function. Programs such as <a href="http://valgrind.org/"><em>Valgrind</em></a> can use this functionality, for example, to track memory leaks at run-time by tracking all allocated and freed memory, or determine when unitialised data is used as if it was initialised (as a branch condition, for example).<br />
		Similarly, programs such as <a href="https://github.com/KDE/heaptrack"><em>Heaptrack</em></a> use <a href="https://en.wikipedia.org/wiki/Hooking">hooks</a> in order to profile memory usage. As such, it requires no changes to the actual source or files included for compilation. However, in order to get more detailed information about allocations (such as the line in the source where it occurs), debug symbols must be included in the binary, which involves a minor change to the compilation procedure.<br />
		As has been the trend in this section, the increased convenience comes with a decrease in tunability. However, again in comes with an improvement in ease of consumption of data - <em>Heaptrack</em> is a two part tool, one producing a detailed dump while the other consumes the dump to produce a large number of statistics and graphics.</p>
		<h2 id="allocator-methods-and-their-performance">Allocator Methods and their Performance</h2>
		<p>(heap v stack, mallocperf)</p>
		<h2 id="validation-of-project-space">Validation of Project Space</h2>
		<p>(uniprocessor, predictors)</p>
		<h2 id="results">Results</h2>
		<p>There are two sets of results to discuss (one for each of the case studies). While the real world case study was less than impressive, there are a few points to moderate it.</p>
		<h3 id="specialised-benchmarks">Specialised Benchmarks</h3>
		<p>The specialised benchmarks, being constructed to be an ideal case, clearly validate that the optimisation can be worthwhile in specific cases.</p>
		<p>That being said, they also serve a reminder that even in simple code there may be hidden issues and complexity, in particular <code>alloca</code>'s performance under <code>O0</code> in both the parallel and sort benchmarks and the unexpected drop in the dynamic method's performance under <code>O3</code> in the sort benchmark.</p>
		<p>Lastly, it also highlights that in certain cases the optimisation makes no performance difference (a wash by 16 items in the sort benchmark, minimal by 64 items in the parallel benchmark) in certain cases while still having the negative effects (very large stack, increased risk of stack overflow, programmer error leading to escaping pointers to stack allocated items).</p>
		<h3 id="curl-benchmarks">cURL Benchmarks</h3>
		<p>With Stenberg's claims about performance increases and removal huge amounts of <code>malloc</code>s, the results found are quite disappointing, being indistinguishable from variance in the test environment itself.</p>
		<p>However, this doesn't mean the optimisation isn't worth performing. Compiler optimisations produce minimal performance benefits over time, and build up mutually to more significant gains over time and in conjuction with each other.</p>
		<p>This was somewhat formalised by <a href="http://proebsting.cs.arizona.edu/law.html">Proebsting's Law</a> (Todd A. Proebsting of University of Arizona), which claimed &quot;compiler optimization advances double computing power every 18 years&quot;, with figures chosen to reasonably match up with the better known Moore's Law. This is equivalent to 4% increases per year, which makes even vanishingly small improvements in any given case seem better by comparison.</p>
		<p>Proebsting's law is further researched in <em>On Proebsting’s law, Scott, 2001</em>, in which Scott finds it to most likely be true, producing a range of possibly figures for yearly improvement between 2.8-4.9% depending on a few factors.<br />
		However, this doesn't mean optimisations aren't worthwhile. He also refers to a lecture by Bill Pugh (University of Maryland) titled <em>Is Code Optimization (Research) Relevant</em>, created in response to Proebsting's Law, in which Pugh argues no one will turn down a free performance improvement from compiler optimisations, but suggests that focus on producing optimisations for high-level constructs to free up programmers to be more productive could be more worthwhile.</p>
	</body>
</html>
