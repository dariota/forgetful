<html>
	<head>
		<title>ntun.es - forgetful project</title>
		<link rel="stylesheet" type="text/css" href="styles/default.css">
	</head>
	<body>
		<h1>What's this?</h1>
		<p>Some data gathered that I'm trying to figure out.</p>
		<p>I'm comparing the performance of various ways to allocate memory compared to <code>malloc</code>.</p>
		<h2>cURL Benchmarks</h2>
		<p>Comparing two commits mentioned in the <a href="https://daniel.haxx.se/blog/2017/04/22/fewer-mallocs-in-curl/">Fewer mallocs in curl</a> blog post to their parent commits, in order to isolate their effect on performance.</p>
		<p>In the blog post, the changes are lumped together with a number of other changes in between releases of cURL when doing benchmarking, which could obscure the impact of the changes of interest.</p>
		<h3>multi-wait changes</h3>
		<p>The multi-wait library function was changed to use the stack instead of <code>malloc</code> in a common case where a small amount of data is allocated. This cut down (according to Stenberg's own measurements) the number of <code>malloc</code>s in a simple test by 99.67%.</p>
		<p>In order to test this, the <code>multi-single.c</code> example was modified to download from 1 or 11 file descriptors (as the limit on wulti-wait puts up to 10 file descriptors on the stack), then used to download a 1GB empty file from a local python server.</p>
		<p>The times are then compared to the times taken to do the same in the parent commit.</p>
		<h2>Specialised Benchmarks</h2>
		<p>There are two benchmarks, the source of which are in <a href="https://github.com/dariota/forgetful/tree/master/src">the project repo</a>.
			<ol>
				<li>
					The sort benchmark is light on allocations, and performs the following a fixed number of times (10-20 thousand times per allocation type).</br>
					It performs one single allocation, then copies input data (a struct containing a random int and a sequential ID, which is populated but never used) into that buffer before sorting the data, using the random int as the key.</br>
					To sort, it uses <a href="https://android.googlesource.com/platform/bionic.git/+/eclair-release/libc/stdlib/qsort.c">this qsort</a>, as <a href="https://github.com/KDE/heaptrack">heaptrack</a> indicated that the stdlib qsort (from glibc2.26-11 on Arch Linux) was performing a significant number of allocations, which were affecting the benchmark. I'll be investigating this later, should I have time.
				</li>
				<li>
					The parallel benchmark is heavy on allocations and parallelism, light on other behaviour. It executes for a fixed amount of time (executing once, then checking a flag for whether it should continue, and so on).</br>
					Each execution allocates a buffer, and then copies all the values over from the input buffer. This is done by 4 threads in parallel (all copying from the same input buffer to different target buffers), to maximise contention of <code>malloc</code>'s lock.</br>
					The number of times it executes is tracked, then the number of operations per second is determined (in case execution continued past the fixed amount of time if the timing thread was asleep).
				</li>
			</ol>
		</p>
		<p>
		The types of allocation are explained below:
			<ul>
				<li>Dynamic - Uses a fixed size stack allocated buffer, and if the input data doesn't fit in that buffer it uses <code>malloc</code> instead. The static buffer in these benchmarks is of 64 items</li>
				<li>External - Rather than allocating its own buffer, uses one that's passed in. Intended as a control, as no allocation is done</li>
				<li>Malloc - Uses <code>malloc</code></li>
				<li>Stack - Uses <code>alloca</code></li>
			</ul>
		<p>
		<h3>Predictions:</h3>
		<p>Performance is expected to roughly follow the following for 64 or less items:
		<ol>
			<li>External: As the control, performing no allocations, it should perform fastest as it's plainly doing less work</li>
			<li>Stack: Allocating on the stack should be fast, and for the benchmark allocations are simply performed using alloca</li>
			<li>Dynamic: Should perform similarly to stack, or possibly faster depending on how efficient alloca is (as the space can be allocated along with the rest of the stack frame)</li>
			<li>Malloc: Has to perform all the usual work in order to produce space, so should be slowest</li>
		</ol>
		</p>
		<p>For 64 or more items, the dynamic allocator falls back to <code>malloc</code>, along with the added (small) overhead of determining whether to use <code>malloc</code> or the stack. However, with the benchmark running multiple times with the same conditions, the branch predictor should be able to effectively optimise that out, leaving it equivalent to <code>malloc</code>. The rest should remain relatively unchanged.</p>
		<p>In general, performance of all allocators should converge as the number of items increases and relatively less time is spent in allocation.</p>
		<h3>Results for sort benchmark:</h3>
		<p><strong>Note:</strong> values less than 1 outperform <code>malloc</code>.</p>
		<figure>
			<img src="img/naive/O0chart.png" class="forgetful"/>
			<figcaption>Unexpectedly, <code>alloca</code> performs <strong>worse</strong> than <code>malloc</code>. Others perform as expected. From inspecting the generated assembly, it looks like <code>-O0</code> produces very inefficient code for <code>alloca</code>.</figcaption>
		</figure> 
		<figure>
			<img src="img/naive/O1chart.png" class="forgetful"/>
			<figcaption>Everything performing mostly as expected. Stack and dynamic seem to perform very similarly, with dynamic unexpectedly underperforming <code>malloc</code> even before falling back to <code>malloc</code> itself. This happens around the same time as the other methods converge with <code>malloc</code>.</figcaption>
		</figure> 
		<figure>
			<img src="img/naive/O2chart.png" class="forgetful"/>
			<figcaption>Everything mostly as expected. Dynamic shouldn't be faster than stack, but they're close enough after the first item that I'm not too concerned.</figcaption>
		</figure> 
		<figure id="inlineissue">
			<img src="img/naive/O3chart.png" class="forgetful"/>
			<figcaption>This one's weird. Dynamic performing even worse than <code>alloca</code> did with <code>-O0</code>. Tracked it down to something to do with <code>-finline-functions</code>. It turns out that the dynamic benchmark is split into two cases - one for when the stack is used, another for when malloc is used - and the correct case jumped to at the start. When the perform_busy_work function gets inlined, it gets optimised to a call to memcpy followed by a call to nqsort, but only in the malloc case. This means that the stack case performs worse by comparison as it's using a less efficient method to copy the buffers over.</figcaption>
		</figure> 
		<figure>
			<img src="img/naive/O3chart-no-inline.png" class="forgetful"/>
			<figcaption>Same as the above with <code>-fno-inline-functions</code>.</figcaption>
		</figure> 
		<h3>Results for parallel benchmark:</h3>
		<p><strong>Note:</strong> values greater than 1 outperform <code>malloc</code>.</p>
		<figure>
			<img src="img/parallel/O0chart.png" class="forgetful"/>
			<figcaption><code>alloca</code> underperforming again, other two performing as expected.</figcaption>
		</figure>
		<figure>
			<img src="img/parallel/O1chart.png" class="forgetful"/>
			<figcaption>Stack and dynamic performing almost identically, unusually.</figcaption>
		</figure>
		<figure>
			<img src="img/parallel/O2chart.png" class="forgetful"/>
			<figcaption>The benchmark functions other than external get optimised out, so this bit's irrelevant.</figcaption>
		</figure>
		<figure>
			<img src="img/parallel/O3chart.png" class="forgetful"/>
			<figcaption>The benchmark functions other than external get optimised out, so this bit's irrelevant.</figcaption>
		</figure>
	</body>
</html>
